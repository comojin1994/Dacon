{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Library & Preprocess Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GPU = f'0'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=GPU\n",
    "import random\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ReduceLROnPlateau,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TensorBoard\n",
    ")\n",
    "from tensorflow.keras.applications import (\n",
    "    MobileNet,\n",
    "    MobileNetV2,\n",
    "    EfficientNetB7\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    GlobalAveragePooling2D,\n",
    "    Dense\n",
    ")\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "classes = 1049\n",
    "size = 600\n",
    "\n",
    "learning_rate = 1e-2\n",
    "wd = 0.0005\n",
    "max_lr = 1e-2\n",
    "min_lr = 5e-5\n",
    "cycle_len = 20\n",
    "\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['landmark_id'] = df['landmark_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Train & Valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datagenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='id',\n",
    "    y_col='landmark_id',\n",
    "    target_size=(size,size),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='id',\n",
    "    y_col='landmark_id',\n",
    "    target_size=(size,size),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(f'/device:GPU:{GPU}'):\n",
    "    base_model = EfficientNetB7(\n",
    "        input_shape=(size,size,3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tfa.optimizers.AdamW(learning_rate, wd)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = './checkpoints/mobilenetv2/'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=False,\n",
    "                                                monitor='val_accuracy', mode='max', save_best_only=True,\n",
    "                                        verbose=1)\n",
    "\n",
    "def trianfle_fn(x):\n",
    "    return 1. / (2.**(x - 1))\n",
    "clr_f = tfa.optimizers.CyclicalLearningRate(\n",
    "    initial_learning_rate = max_lr,\n",
    "    maximal_learning_rate = min_lr,\n",
    "    step_size = cycle_len,\n",
    "    scale_fn = trianfle_fn\n",
    ")\n",
    "\n",
    "learing_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(clr_f)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, \n",
    "                                          verbose=2, mode='auto', baseline=None, \n",
    "                                          restore_best_weights=True)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [checkpoint, learing_rate_scheduler, early_stop, tensorboard_callback]\n",
    "\n",
    "# delete checkpoint\n",
    "# callbacks = [learing_rate_scheduler, early_stop, tensorboard_callback]\n",
    "\n",
    "# delete EarlyStop\n",
    "# callbacks = [checkpoint, learing_rate_scheduler, tensorboard_callback]\n",
    "\n",
    "# Only Scheduler\n",
    "# callbacks = [learing_rate_scheduler, tensorboard_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Landmark",
   "language": "python",
   "name": "landmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
